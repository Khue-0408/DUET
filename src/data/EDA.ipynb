{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DUET Datasets EDA\n",
        "\n",
        "Notebook n\u00e0y gi\u00fap b\u1ea1n:\n",
        "1) Scan nhi\u1ec1u polyp segmentation datasets theo layout th\u1ed1ng nh\u1ea5t (codebase DUET).\n",
        "2) Th\u1ed1ng k\u00ea domain shift (color/texture/edge) gi\u1eefa datasets, centers, modalities.\n",
        "3) Ph\u00e2n t\u00edch small polyp v\u00e0 boundary difficulty (\u0111\u1ed9 m\u1ea3nh/\u0111\u1ed9 ph\u1ee9c t\u1ea1p bi\u00ean).\n",
        "\n",
        "Y\u00eau c\u1ea7u: b\u1ea1n \u0111\u00e3 t\u1ef1 t\u1ea3i dataset v\u1ec1 m\u00e1y v\u00e0 \u0111\u1eb7t \u0111\u00fang c\u1ea5u tr\u00fac th\u01b0 m\u1ee5c \u1edf `DATA_ROOT`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Setup\n",
        "\n",
        "C\u00e0i th\u00eam n\u1ebfu thi\u1ebfu:\n",
        "```bash\n",
        "pip install numpy pandas matplotlib scikit-learn scikit-image pillow tqdm\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from skimage.color import rgb2hsv\n",
        "from skimage.feature import canny\n",
        "from skimage.filters import sobel\n",
        "from skimage.segmentation import find_boundaries\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "plt.rcParams['figure.dpi'] = 130\n",
        "\n",
        "DATA_ROOT = Path(os.environ.get('DUET_DATA_ROOT', './data'))\n",
        "print('DATA_ROOT =', DATA_ROOT.resolve())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Expected folder layout\n",
        "\n",
        "Notebook (v\u00e0 codebase) \u0111\u1ecdc theo layout th\u1ed1ng nh\u1ea5t, v\u00ed d\u1ee5:\n",
        "\n",
        "```\n",
        "data/\n",
        "  kvasir_seg/\n",
        "    images/\n",
        "    masks/\n",
        "  cvc_clinicdb/\n",
        "    images/\n",
        "    masks/\n",
        "  cvc_colondb/\n",
        "    images/\n",
        "    masks/\n",
        "  etis_larib/\n",
        "    images/\n",
        "    masks/\n",
        "  polypdb/\n",
        "    WLI/images/  WLI/annotations/\n",
        "    NBI/images/  NBI/annotations/\n",
        "    ...\n",
        "    splits/\n",
        "      train.txt\n",
        "      test.txt\n",
        "  polypgen/\n",
        "    images/\n",
        "      positive/\n",
        "      negative/\n",
        "    masks/\n",
        "      positive/\n",
        "    splits/\n",
        "      loco_fold_1_train.txt\n",
        "      loco_fold_1_test.txt\n",
        "      ...\n",
        "    meta/\n",
        "      center_map.csv   # optional: image_id -> center_id\n",
        "```\n",
        "\n",
        "Ch\u1ec9 c\u1ea7n \u0111\u00fang c\u00e1c folder `images/` v\u00e0 `masks/` l\u00e0 EDA ch\u1ea1y \u0111\u01b0\u1ee3c; `splits/` gi\u00fap t\u00e1ch train/test/LOCO.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class DatasetSpec:\n",
        "    name: str\n",
        "    images_glob: str\n",
        "    masks_glob: Optional[str]  # None for unlabeled\n",
        "    id_from_path: bool = True  # map by stem\n",
        "\n",
        "\n",
        "SPECS: Dict[str, DatasetSpec] = {\n",
        "    'kvasir_seg': DatasetSpec('kvasir_seg', 'kvasir_seg/images/*', 'kvasir_seg/masks/*'),\n",
        "    'cvc_clinicdb': DatasetSpec('cvc_clinicdb', 'cvc_clinicdb/images/*', 'cvc_clinicdb/masks/*'),\n",
        "    'cvc_colondb': DatasetSpec('cvc_colondb', 'cvc_colondb/images/*', 'cvc_colondb/masks/*'),\n",
        "    'etis_larib': DatasetSpec('etis_larib', 'etis_larib/images/*', 'etis_larib/masks/*'),\n",
        "    # PolypDB modality-wise layout (default from OSF wiki)\n",
        "    'polypdb_WLI': DatasetSpec('polypdb_WLI', 'polypdb/WLI/images/*', 'polypdb/WLI/annotations/*'),\n",
        "    'polypdb_NBI': DatasetSpec('polypdb_NBI', 'polypdb/NBI/images/*', 'polypdb/NBI/annotations/*'),\n",
        "    'polypdb_BLI': DatasetSpec('polypdb_BLI', 'polypdb/BLI/images/*', 'polypdb/BLI/annotations/*'),\n",
        "    'polypdb_LCI': DatasetSpec('polypdb_LCI', 'polypdb/LCI/images/*', 'polypdb/LCI/annotations/*'),\n",
        "    'polypdb_FICE': DatasetSpec('polypdb_FICE', 'polypdb/FICE/images/*', 'polypdb/FICE/annotations/*'),\n",
        "    # PolypGen positive/negative (unified layout)\n",
        "    'polypgen_pos': DatasetSpec('polypgen_pos', 'polypgen/images/positive/*', 'polypgen/masks/positive/*'),\n",
        "    'polypgen_neg': DatasetSpec('polypgen_neg', 'polypgen/images/negative/*', None),\n",
        "}\n",
        "\n",
        "\n",
        "def _list_files(pattern: str) -> List[Path]:\n",
        "    return sorted([p for p in DATA_ROOT.glob(pattern) if p.is_file()])\n",
        "\n",
        "\n",
        "def scan_dataset(spec: DatasetSpec) -> pd.DataFrame:\n",
        "    imgs = _list_files(spec.images_glob)\n",
        "    if len(imgs) == 0:\n",
        "        return pd.DataFrame(columns=['dataset', 'image_path', 'mask_path', 'image_id'])\n",
        "\n",
        "    if spec.masks_glob is None:\n",
        "        df = pd.DataFrame({'dataset': spec.name, 'image_path': imgs})\n",
        "        df['mask_path'] = None\n",
        "        df['image_id'] = df['image_path'].apply(lambda p: Path(p).stem)\n",
        "        return df\n",
        "\n",
        "    masks = _list_files(spec.masks_glob)\n",
        "    mask_map = {m.stem: m for m in masks}\n",
        "\n",
        "    rows = []\n",
        "    for im in imgs:\n",
        "        iid = im.stem\n",
        "        mp = mask_map.get(iid, None)\n",
        "        # fallback: some datasets use different suffixes\n",
        "        if mp is None:\n",
        "            for k, v in mask_map.items():\n",
        "                if k.startswith(iid) or iid.startswith(k):\n",
        "                    mp = v\n",
        "                    break\n",
        "        rows.append({'dataset': spec.name, 'image_path': im, 'mask_path': mp, 'image_id': iid})\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    return df\n",
        "\n",
        "\n",
        "dfs = []\n",
        "for key, spec in SPECS.items():\n",
        "    df = scan_dataset(spec)\n",
        "    if len(df) > 0:\n",
        "        dfs.append(df)\n",
        "\n",
        "data_index = pd.concat(dfs, ignore_index=True) if len(dfs) else pd.DataFrame()\n",
        "print('Total samples:', len(data_index))\n",
        "data_index['has_mask'] = data_index['mask_path'].notna()\n",
        "display(data_index.groupby('dataset')[['image_id','has_mask']].count().rename(columns={'image_id':'n_images','has_mask':'n_with_mask'}))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Utility: load image/mask safely\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_rgb(path: Path) -> np.ndarray:\n",
        "    img = Image.open(path).convert('RGB')\n",
        "    return np.asarray(img)\n",
        "\n",
        "\n",
        "def read_mask(path: Optional[Path]) -> Optional[np.ndarray]:\n",
        "    if path is None or (isinstance(path, float) and np.isnan(path)):\n",
        "        return None\n",
        "    m = Image.open(path).convert('L')\n",
        "    arr = np.asarray(m)\n",
        "    # binarize (robust across 0/255 or 0/1)\n",
        "    return (arr > 127).astype(np.uint8)\n",
        "\n",
        "\n",
        "def mask_stats(mask: np.ndarray) -> Dict[str, float]:\n",
        "    h, w = mask.shape\n",
        "    area = float(mask.sum())\n",
        "    area_ratio = area / float(h*w)\n",
        "\n",
        "    bnd = find_boundaries(mask.astype(bool), mode='outer')\n",
        "    bnd_len = float(bnd.sum())\n",
        "\n",
        "    # boundary complexity proxy: boundary length per unit area (avoid div0)\n",
        "    comp = bnd_len / (area + 1.0)\n",
        "    bnd_ratio = bnd_len / float(h*w)\n",
        "    return {'area': area, 'area_ratio': area_ratio, 'boundary_len': bnd_len, 'boundary_ratio': bnd_ratio, 'boundary_complexity': comp}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Basic dataset statistics\n",
        "\n",
        "G\u1ed3m: resolution, area ratio, small polyp rate, boundary complexity.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_basic_stats(df: pd.DataFrame, max_items: Optional[int] = None) -> pd.DataFrame:\n",
        "    rows = []\n",
        "    it = df.itertuples(index=False)\n",
        "    if max_items is not None:\n",
        "        it = list(it)[:max_items]\n",
        "\n",
        "    for r in tqdm(it, total=(max_items or len(df))):\n",
        "        img = read_rgb(Path(r.image_path))\n",
        "        h, w = img.shape[:2]\n",
        "        row = {\n",
        "            'dataset': r.dataset,\n",
        "            'image_id': r.image_id,\n",
        "            'H': h,\n",
        "            'W': w,\n",
        "        }\n",
        "        m = read_mask(r.mask_path) if r.mask_path is not None else None\n",
        "        if m is not None:\n",
        "            row.update(mask_stats(m))\n",
        "        rows.append(row)\n",
        "\n",
        "    out = pd.DataFrame(rows)\n",
        "    return out\n",
        "\n",
        "\n",
        "stats = compute_basic_stats(data_index[data_index['has_mask']].copy(), max_items=None)\n",
        "display(stats.head())\n",
        "\n",
        "summary = stats.groupby('dataset').agg(\n",
        "    n=('image_id','count'),\n",
        "    H_mean=('H','mean'),\n",
        "    W_mean=('W','mean'),\n",
        "    area_ratio_median=('area_ratio','median'),\n",
        "    area_ratio_p10=('area_ratio', lambda s: float(np.quantile(s, 0.10))),\n",
        "    area_ratio_p90=('area_ratio', lambda s: float(np.quantile(s, 0.90))),\n",
        "    boundary_complexity_median=('boundary_complexity','median'),\n",
        ").reset_index()\n",
        "display(summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Small polyp analysis\n",
        "\n",
        "DUET nh\u1ea5n m\u1ea1nh nh\u00f3m small polyps (< 5mm). N\u1ebfu dataset kh\u00f4ng c\u00f3 size metadata, ta d\u00f9ng proxy theo di\u1ec7n t\u00edch mask.\n",
        "\n",
        "B\u1ea1n c\u00f3 th\u1ec3 ch\u1ec9nh `SMALL_AREA_RATIO` t\u00f9y theo scale \u1ea3nh (v\u00ed d\u1ee5 0.005 t\u01b0\u01a1ng \u0111\u01b0\u01a1ng 0.5% di\u1ec7n t\u00edch \u1ea3nh).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SMALL_AREA_RATIO = 0.005\n",
        "\n",
        "stats['is_small_proxy'] = stats['area_ratio'] < SMALL_AREA_RATIO\n",
        "small_rate = stats.groupby('dataset')['is_small_proxy'].mean().reset_index().rename(columns={'is_small_proxy':'small_rate_proxy'})\n",
        "display(small_rate)\n",
        "\n",
        "plt.figure()\n",
        "for ds, g in stats.groupby('dataset'):\n",
        "    plt.hist(g['area_ratio'], bins=50, alpha=0.4, label=ds)\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Mask area ratio (log-scale)')\n",
        "plt.ylabel('Count')\n",
        "plt.legend()\n",
        "plt.title('Area ratio distribution by dataset')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Boundary difficulty\n",
        "\n",
        "M\u1ed9t proxy \u0111\u01a1n gi\u1ea3n: `boundary_complexity = boundary_len/(area+1)`.\n",
        "Gi\u00e1 tr\u1ecb cao th\u01b0\u1eddng l\u00e0 polyp nh\u1ecf ho\u1eb7c bi\u00ean ngo\u1eb1n ngo\u00e8o/m\u1edd.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "for ds, g in stats.groupby('dataset'):\n",
        "    plt.hist(g['boundary_complexity'], bins=50, alpha=0.4, label=ds)\n",
        "plt.yscale('log')\n",
        "plt.xlabel('Boundary complexity (boundary_len/(area+1))')\n",
        "plt.ylabel('Count (log)')\n",
        "plt.legend()\n",
        "plt.title('Boundary complexity distribution')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualize examples: overlay mask + boundary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_overlay(img: np.ndarray, mask: np.ndarray, title: str = '') -> None:\n",
        "    bnd = find_boundaries(mask.astype(bool), mode='outer')\n",
        "    overlay = img.copy()\n",
        "    # boundary in red\n",
        "    overlay[bnd] = [255, 0, 0]\n",
        "\n",
        "    plt.figure(figsize=(10,3))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title('Image')\n",
        "\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(mask, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title('Mask')\n",
        "\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(overlay)\n",
        "    plt.axis('off')\n",
        "    plt.title('Overlay (boundary)')\n",
        "    plt.suptitle(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def sample_examples(df_stats: pd.DataFrame, n_per_ds: int = 3, mode: str = 'random') -> None:\n",
        "    for ds, g in df_stats.groupby('dataset'):\n",
        "        if len(g) == 0:\n",
        "            continue\n",
        "        if mode == 'small':\n",
        "            cand = g[g['is_small_proxy']]\n",
        "            if len(cand) == 0:\n",
        "                continue\n",
        "            samp = cand.sample(min(n_per_ds, len(cand)), random_state=0)\n",
        "        elif mode == 'hard_boundary':\n",
        "            samp = g.sort_values('boundary_complexity', ascending=False).head(n_per_ds)\n",
        "        else:\n",
        "            samp = g.sample(min(n_per_ds, len(g)), random_state=0)\n",
        "\n",
        "        for r in samp.itertuples(index=False):\n",
        "            img_path = data_index[(data_index['dataset']==ds) & (data_index['image_id']==r.image_id)].iloc[0]['image_path']\n",
        "            mask_path = data_index[(data_index['dataset']==ds) & (data_index['image_id']==r.image_id)].iloc[0]['mask_path']\n",
        "            img = read_rgb(Path(img_path))\n",
        "            mask = read_mask(mask_path)\n",
        "            show_overlay(img, mask, title=f'{ds} | id={r.image_id} | area_ratio={r.area_ratio:.4f} | bnd_comp={r.boundary_complexity:.3f}')\n",
        "\n",
        "\n",
        "print('Random examples')\n",
        "sample_examples(stats, n_per_ds=2, mode='random')\n",
        "\n",
        "print('Small polyp proxy examples')\n",
        "sample_examples(stats, n_per_ds=2, mode='small')\n",
        "\n",
        "print('Hard boundary examples')\n",
        "sample_examples(stats, n_per_ds=2, mode='hard_boundary')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Domain shift visualization (hand-crafted features)\n",
        "\n",
        "Kh\u00f4ng c\u1ea7n pretrained model. Ta d\u00f9ng feature \u0111\u01a1n gi\u1ea3n:\n",
        "- mean/std RGB\n",
        "- mean HSV\n",
        "- edge density (Canny)\n",
        "- gradient energy (Sobel)\n",
        "- specular highlight ratio (V high, S low)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def image_features(img: np.ndarray) -> np.ndarray:\n",
        "    x = img.astype(np.float32) / 255.0\n",
        "    h, w, _ = x.shape\n",
        "\n",
        "    mean_rgb = x.reshape(-1, 3).mean(axis=0)\n",
        "    std_rgb = x.reshape(-1, 3).std(axis=0)\n",
        "\n",
        "    hsv = rgb2hsv(x)\n",
        "    mean_hsv = hsv.reshape(-1, 3).mean(axis=0)\n",
        "\n",
        "    gray = x.mean(axis=2)\n",
        "    edges = canny(gray, sigma=1.0)\n",
        "    edge_density = edges.mean()\n",
        "\n",
        "    grad = sobel(gray)\n",
        "    grad_energy = float(np.mean(grad**2))\n",
        "\n",
        "    # specular: high V but low saturation\n",
        "    spec = ((hsv[...,2] > 0.90) & (hsv[...,1] < 0.20)).mean()\n",
        "\n",
        "    return np.concatenate([\n",
        "        mean_rgb, std_rgb, mean_hsv,\n",
        "        np.array([edge_density, grad_energy, spec], dtype=np.float32)\n",
        "    ], axis=0)\n",
        "\n",
        "\n",
        "def compute_features(df: pd.DataFrame, max_items_per_ds: int = 300) -> pd.DataFrame:\n",
        "    rows = []\n",
        "    for ds, g in df.groupby('dataset'):\n",
        "        gg = g.sample(min(max_items_per_ds, len(g)), random_state=0)\n",
        "        for r in tqdm(gg.itertuples(index=False), total=len(gg), desc=f'feat {ds}'):\n",
        "            img = read_rgb(Path(r.image_path))\n",
        "            feat = image_features(img)\n",
        "            rows.append({'dataset': ds, 'image_id': r.image_id, 'feat': feat})\n",
        "\n",
        "    out = pd.DataFrame(rows)\n",
        "    feats = np.stack(out['feat'].values, axis=0)\n",
        "    feat_cols = [\n",
        "        'mean_r','mean_g','mean_b','std_r','std_g','std_b',\n",
        "        'mean_h','mean_s','mean_v','edge_density','grad_energy','spec_ratio'\n",
        "    ]\n",
        "    out = pd.concat([out.drop(columns=['feat']).reset_index(drop=True), pd.DataFrame(feats, columns=feat_cols)], axis=1)\n",
        "    return out\n",
        "\n",
        "\n",
        "feat_df = compute_features(data_index.copy(), max_items_per_ds=300)\n",
        "display(feat_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = feat_df.drop(columns=['dataset','image_id']).values\n",
        "\n",
        "pca = PCA(n_components=2, random_state=0)\n",
        "Z = pca.fit_transform(X)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "for ds in sorted(feat_df['dataset'].unique()):\n",
        "    m = feat_df['dataset'] == ds\n",
        "    plt.scatter(Z[m,0], Z[m,1], s=10, alpha=0.6, label=ds)\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')\n",
        "plt.title('PCA on hand-crafted features (domain shift proxy)')\n",
        "plt.legend(markerscale=2, bbox_to_anchor=(1.02, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# t-SNE th\u01b0\u1eddng ch\u1eadm; gi\u1ea3m sample n\u1ebfu c\u1ea7n\n",
        "MAX_TSNE = 1200\n",
        "ts = feat_df.sample(min(MAX_TSNE, len(feat_df)), random_state=0)\n",
        "Xts = ts.drop(columns=['dataset','image_id']).values\n",
        "\n",
        "tsne = TSNE(n_components=2, perplexity=30, learning_rate='auto', init='pca', random_state=0)\n",
        "Zts = tsne.fit_transform(Xts)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "for ds in sorted(ts['dataset'].unique()):\n",
        "    m = ts['dataset'] == ds\n",
        "    plt.scatter(Zts[m,0], Zts[m,1], s=10, alpha=0.6, label=ds)\n",
        "plt.title('t-SNE on hand-crafted features')\n",
        "plt.legend(markerscale=2, bbox_to_anchor=(1.02, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Boundary contrast proxy (t\u1ea1i sao bi\u00ean m\u1edd g\u00e2y kh\u00f3)\n",
        "\n",
        "M\u1ed9t proxy: ch\u00eanh l\u1ec7ch gradient magnitude gi\u1eefa boundary band v\u00e0 background band.\n",
        "Gi\u00e1 tr\u1ecb th\u1ea5p ngh\u0129a l\u00e0 bi\u00ean kh\u00f3 ph\u00e2n t\u00e1ch (low-contrast boundary).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from skimage.morphology import binary_dilation, binary_erosion, disk\n",
        "\n",
        "def boundary_contrast_proxy(img: np.ndarray, mask: np.ndarray, r: int = 3) -> float:\n",
        "    x = img.astype(np.float32) / 255.0\n",
        "    gray = x.mean(axis=2)\n",
        "    grad = sobel(gray)\n",
        "\n",
        "    se = disk(r)\n",
        "    core = binary_erosion(mask.astype(bool), se)\n",
        "    dil = binary_dilation(mask.astype(bool), se)\n",
        "    bnd_band = dil & (~core)\n",
        "    bg_band = binary_dilation(dil, se) & (~dil)\n",
        "\n",
        "    bnd_val = float(np.mean(grad[bnd_band])) if bnd_band.any() else 0.0\n",
        "    bg_val = float(np.mean(grad[bg_band])) if bg_band.any() else 0.0\n",
        "    return bnd_val - bg_val\n",
        "\n",
        "\n",
        "def compute_boundary_contrast(df: pd.DataFrame, max_items_per_ds: int = 300) -> pd.DataFrame:\n",
        "    rows = []\n",
        "    for ds, g in df.groupby('dataset'):\n",
        "        gg = g.sample(min(max_items_per_ds, len(g)), random_state=0)\n",
        "        for r in tqdm(gg.itertuples(index=False), total=len(gg), desc=f'contrast {ds}'):\n",
        "            img = read_rgb(Path(r.image_path))\n",
        "            mask = read_mask(r.mask_path)\n",
        "            if mask is None:\n",
        "                continue\n",
        "            c = boundary_contrast_proxy(img, mask, r=3)\n",
        "            rows.append({'dataset': ds, 'image_id': r.image_id, 'boundary_contrast_proxy': c})\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "contrast_df = compute_boundary_contrast(data_index[data_index['has_mask']].copy(), max_items_per_ds=250)\n",
        "display(contrast_df.groupby('dataset')['boundary_contrast_proxy'].describe())\n",
        "\n",
        "plt.figure()\n",
        "for ds, g in contrast_df.groupby('dataset'):\n",
        "    plt.hist(g['boundary_contrast_proxy'], bins=50, alpha=0.4, label=ds)\n",
        "plt.xlabel('Boundary contrast proxy (Sobel boundary band minus bg band)')\n",
        "plt.ylabel('Count')\n",
        "plt.legend()\n",
        "plt.title('Boundary contrast proxy distribution')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.1 Visualize low-contrast boundary examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_low_contrast_examples(k: int = 12):\n",
        "    merged = contrast_df.merge(data_index[['dataset','image_id','image_path','mask_path']], on=['dataset','image_id'], how='left')\n",
        "    hard = merged.sort_values('boundary_contrast_proxy', ascending=True).head(k)\n",
        "    for r in hard.itertuples(index=False):\n",
        "        img = read_rgb(Path(r.image_path))\n",
        "        mask = read_mask(r.mask_path)\n",
        "        show_overlay(img, mask, title=f'LOW boundary contrast | {r.dataset} | {r.image_id} | proxy={r.boundary_contrast_proxy:.4f}')\n",
        "\n",
        "\n",
        "show_low_contrast_examples(k=6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Save summary tables\n",
        "\n",
        "Xu\u1ea5t ra CSV \u0111\u1ec3 \u0111\u01b0a v\u00e0o report/slide.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "out_dir = Path('./eda_outputs')\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "stats.to_csv(out_dir/'mask_stats.csv', index=False)\n",
        "feat_df.to_csv(out_dir/'domain_features.csv', index=False)\n",
        "contrast_df.to_csv(out_dir/'boundary_contrast.csv', index=False)\n",
        "\n",
        "print('Saved to', out_dir.resolve())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}